# 알고리즘의 성능분석 방법

- 지수식(y = 2^x) / 로그식(y = log2x)
  - x축: 데이터의 개수
  - y축: 수의 데이터를 연산 처리하는데 걸리는 시간

## 시간 복잡도 & 공간 복잡도1

- 알고리즘을 평가하는 두가지 요소
  - 시간 복잡도 => 얼마나 빠른가(=CPU에게 얼마나 부담을 주는지) 더중요함!!!!
  - 공간 복잡도 => 얼마나 메모리를 적게 쓰는가
- 시간 복잡도의 평가 방법
  - 중심이 되는 특정 연산의 횟수를 세어서 평가
  - 데이터의 수에 대한 연산횟수의 함수 T(n)을 구함 => 그래프로 그릴 수 있으므로 함수로 구현
- 알고리즘의 수행 속도 비교 기준
  - 데이터의 수가 적은 경우의 수행 속도는 큰 의미가 없음
  - 데이터의 수에 따른 수행 속도의 변화 정도를 기준으로 함

### 순차 탐색 알고리즘(LSearch.c)

- 찾고자 하는 값을 만나면 break
- 시간 복잡도를 결정할 연산자(중심이 되는 것)
  - 찾고자 하는 대상을 확인하는 것이 **중심** => if(arr[i] == target){}
  - 주변 연산자들의 연산 횟수(빈도수)는 중심이 되는 연산자의 연산 횟수에 의존적임

#### 최악의 경우와 최상의 경우(시간 복잡도)

- 순차 탐색 상황1 : 운이 좋은 경우 (T(n) = 1)
  - 배열의 맨 앞에서 대상 찾음 => 성능평가의 주 관심은 아님. 'best case'
- 순차 탐색 상황1 : 운이 좋은 경우 (T(n) = n)
  - 배열에 끝에서 대상 찾거나 값이 없는 경우 => 'worst case'

#### 평균적 시간 복잡도 T(n)

- 가정1) 탐색 대상이 배열에 존재하지 않을 확률 50%
- 가정2) 배열 첫 요소부터 마지막 요소까지 탐색 대상 존재 확률 동일!
- T(n) = n \* (1/2) + (n/2) \* (1/2) = 3/4
- 탐색 대상이 존재하지 않는 경우의 연산횟수는 n
- 가정 2에 의해서 탐색 대상이 존재하는 경우의 연산횟수는 n/2

### 이진 탐색 알고리즘(BSearch.c)

- 순차 탐색보다 훨씬 좋은 성능을 보이지만, 배열이 정렬되어있어야함

1. 처음 인덱스와 마지막 인덱스를 합하고 2로 나누어 가운데 인덱스 구하기
2. 내가 찾는 값이 존재하는지 확인(대소 비교)해 탐색 범위를 인덱스 기준 제한

- 이진 탐색의 매 과정마다 탐색의 대상을 반씩 줄여나가기 때문에 순차 탐색보다 좋은 성능을 보임
- 탐색 타겟(찾고자 하는 값)이 범위 내 저장되어있지 않은 경우
  - first와 last가 만났다 => 탐색 대상이 하나 남았음
  - first와 last가 역전될 때까지 탐색의 과정 계속 진행

#### 최악의 경우 시간 복잡도

- target == arr[mid] 연산자가 핵심 연산자이므로 이 연산의 횟수를 기준으로 시간 복잡도를 결정 가능
- n개의 데이터에 찾는 값이 저장되어있지 않는다면 => n/2 => n/4 => ... => 최후 한개 남았을 때도 확인 => 1이 될때까지
- n이 얼마인지 결정되지 않았으니 몇 번의 비교연산 진행되었는지 알 수 없음(객관적으로 성능 비교 불가능)

1. n이 1이 되기까지 2로 나눈 횟수 k회 => 비교연산 k회 진행
2. 데이터가 1개 남았을 때 마지막으로 비교연산 1회 진행
   => 최악의 경우 시간 복잡도 함수 T(n) = k + 1
3. k를 구하기 위해  
   n \* ((1/2)^k) = 1  
   n \* (2^(-k)) = 1
   n = 2^k
   log2n = log2(2^k)
   log2n = klog2(2)
   log2n = k

- T(n) = log2(n+1)이지만 +1은 생략 가능하므로 **T(n) = log2(n)**
  - 시간 복잡도의 목적은 n의 값에 따른 T(n)의 증가 및 감소의 정도를 판단하는 것 이므로 +1 생략 가능한 것

#### 이진탐색 알고리즘 최악의 경우 시간 복잡도 5

- T(n) = n^2 + 3 => T(n) = n^2
- T(n) = n^2 \* 100 => T(n) = n^2
- 처리해야 할 데이터의 수가 급격히 증가하는 경우 알고리즘의 성능이 급격히 떨어지는지? 서서히 떨어지는지?
  - = n의 수가 많은 경우
  - 뒤에 연산하는 상수가 크다면..(T(n) = n^2 + 1000000000) 이건 알고리즘이 맞지 않은 것..

#### 빅-오 표기법

- T(n)에서 **실제로 영향력을 끼치는 부분**을 가리켜 빅-오(Big-Oh)
- => n의 변화에 따른 T(n)의 변화 정도를 판단하는 것이 목적이니 +1은 무시할 수 있음
- => 2n도 근사치 식의 구성에서 제외시킬수 있음을 보인 결과. n이 증가함에 따라 2n + 1이 차지하는 비율은 미미
- T(n) = n^2 + 2n + 1 => 1차 근사치 식
- T(n) = n^2 + 2n => 2차 근사치 식
- T(n) = n^2 => T(n)의 빅-오
- O(N^2) => 빅-오 표기 방법

##### 단순하게 빅-오 구하기

- 빅-오는?
  - T(n)이 다항식으로 표현이 된 경우, 최고차항의 차수가 빅-오가 됨
  - 기울기의 패턴을 가지고만 이야기하는 것
- 빅-오 결정의 예
  - T(n) = n^2 + 2n + 9 => O(n^2)
  - T(n) = n^4 + n^3 + n^2 + 1 => O(n^4)
  - T(n) = 5n^3 + 3n^2 + 2n + 1 => O(n^3)
  - => 최고차항의 차수를 빅오로 결정
- 빅-오 결정의 일반화

  - T(n) = a(m)n^m + a(m-1)n^(m-1) + ... + a(1)n^1 + a(0) => O(n^m)

- 대표적인 빅-오
  - O(1)상수형 빅오 < **O(logn)로그형 빅오(연산횟수는 정해짐)** < O(n) < O(nlogn) < O(n^2) < O(n^3) < O(2^n) 지수형 빅오
